{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d9c224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\registration.py:604: UserWarning: \u001b[33mWARN: plugin: shimmy.registration:register_gymnasium_envs raised Traceback (most recent call last):\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\gymnasium\\envs\\registration.py\", line 602, in load_plugin_envs\n",
      "    fn()\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\shimmy\\registration.py\", line 263, in register_gymnasium_envs\n",
      "    _register_atari_envs()\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\shimmy\\registration.py\", line 207, in _register_atari_envs\n",
      "    _register_atari_configs(\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\shimmy\\registration.py\", line 131, in _register_atari_configs\n",
      "    from ale_py.roms import utils as rom_utils\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\ale_py\\roms\\__init__.py\", line 94, in <module>\n",
      "    _RESOLVED_ROMS = _resolve_roms()\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\ale_py\\roms\\__init__.py\", line 46, in _resolve_roms\n",
      "    supported, unsupported = package.resolve()\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\ale_py\\roms\\utils.py\", line 60, in resolve\n",
      "    lambda file: file.suffix == \".bin\", resources.files(self.package).iterdir()\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\importlib_resources\\_common.py\", line 46, in wrapper\n",
      "    return func(anchor)\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\importlib_resources\\_common.py\", line 56, in files\n",
      "    return from_package(resolve(anchor))\n",
      "  File \"C:\\Software\\anaconda3\\lib\\functools.py\", line 889, in wrapper\n",
      "    return dispatch(args[0].__class__)(*args, **kw)\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\importlib_resources\\_common.py\", line 82, in _\n",
      "    return importlib.import_module(cand)\n",
      "  File \"C:\\Software\\anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\atari_py\\__init__.py\", line 1, in <module>\n",
      "    from .ale_python_interface import *\n",
      "  File \"C:\\Software\\anaconda3\\lib\\site-packages\\atari_py\\ale_python_interface.py\", line 17, in <module>\n",
      "    ale_lib = cdll.LoadLibrary(os.path.join(os.path.dirname(__file__),\n",
      "  File \"C:\\Software\\anaconda3\\lib\\ctypes\\__init__.py\", line 452, in LoadLibrary\n",
      "    return self._dlltype(name)\n",
      "  File \"C:\\Software\\anaconda3\\lib\\ctypes\\__init__.py\", line 374, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "FileNotFoundError: Could not find module 'C:\\Software\\anaconda3\\lib\\site-packages\\atari_py\\ale_interface\\ale_c.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "\u001b[0m\n",
      "  logger.warn(f\"plugin: {plugin.value} raised {traceback.format_exc()}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from env import MarketSimulation\n",
    "from utils import get_options\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.distributions import Normal\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "seed = 10\n",
    "\n",
    "LAMBDA = 0.95\n",
    "GAMMA = 0.99\n",
    "\n",
    "ACTOR_LR = 2e-4\n",
    "CRITIC_LR = 2e-4\n",
    "\n",
    "CLIP = 0.2\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "ITERATIONS = 10000\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e8397a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.Sequential(nn.BatchNorm1d(int(state_dim/2)),\n",
    "                                   nn.Flatten(),\n",
    "                                   nn.Linear(state_dim, 256),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Linear(256, 256),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Linear(256, action_dim)).to(device)\n",
    "        \n",
    "        self.sigma = nn.Parameter(torch.zeros((action_dim))).to(device)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def compute_proba(self, state, action):\n",
    "        _, _, distribution = self.act(state)\n",
    "        return torch.exp(distribution.log_prob(action).sum(-1))\n",
    "\n",
    "    def act(self, state):\n",
    "        means = self.model(state)\n",
    "        stds = torch.exp(self.sigma).expand_as(means)\n",
    "        distribution = torch.distributions.Normal(means, stds)\n",
    "        \n",
    "        action = distribution.sample()\n",
    "        tanh_action = self.tanh(action)\n",
    "        return tanh_action, action, distribution\n",
    "\n",
    "    \n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(nn.BatchNorm1d(int(state_dim/2)),\n",
    "                                   nn.Flatten(),\n",
    "                                   nn.Linear(state_dim, 256),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Linear(256, 256),\n",
    "                                   nn.ELU(),\n",
    "                                   nn.Linear(256, 1)).to(device)\n",
    "\n",
    "    def get_value(self, state):\n",
    "        return self.model(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22394a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, agent_id, actives, money, state_dim, action_dim):\n",
    "        self.agent_id = agent_id\n",
    "        self.actives = actives\n",
    "        self.money = money\n",
    "        \n",
    "        self.open = False\n",
    "        self.request = None\n",
    "        self.num_iterations = None\n",
    "        \n",
    "        self.actor = Actor(state_dim, action_dim).to(device)\n",
    "        self.critic = Critic(state_dim).to(device)\n",
    "        self.actor_optim = Adam(self.actor.parameters(), ACTOR_LR)\n",
    "        self.critic_optim = Adam(self.critic.parameters(), CRITIC_LR)\n",
    "\n",
    "    def update(self, trajectories):\n",
    "        state, action, old_prob, target_value, advantage = zip(*trajectories)\n",
    "        state = np.array(state)\n",
    "        action = np.array(action)\n",
    "        old_prob = np.array(old_prob)\n",
    "        target_value = np.array(target_value)\n",
    "        advantage = np.array(advantage)\n",
    "        advnatage = (advantage - advantage.mean()) / (advantage.std() + 1e-8)\n",
    "        \n",
    "        s = torch.tensor(state).float().to(device)\n",
    "        a = torch.tensor(action).float().to(device)\n",
    "        op = torch.tensor(old_prob).float().to(device)\n",
    "        v = torch.tensor(target_value).float().to(device)\n",
    "        adv = torch.tensor(advantage).float().to(device)\n",
    "\n",
    "        prob = self.actor.compute_proba(s, a)\n",
    "        ratio = prob / op\n",
    "        surr1 = ratio * adv\n",
    "        surr2 = torch.clamp(ratio, 1 - CLIP, 1 + CLIP) * adv\n",
    "        actor_loss = - torch.min(surr1, surr2).mean()\n",
    "        self.actor_optim.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        self.actor_optim.step()   \n",
    "\n",
    "        value = self.critic.get_value(s)\n",
    "        target = v.unsqueeze(1)\n",
    "        critic_loss = F.smooth_l1_loss(value, target)\n",
    "        self.critic_optim.zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optim.step()\n",
    "\n",
    "    def get_value(self, state):\n",
    "        with torch.no_grad():\n",
    "            state = torch.tensor(np.array([state])).float().to(device)\n",
    "            value = self.critic.get_value(state)\n",
    "        return value.cpu().item()\n",
    "\n",
    "    def act(self, state):\n",
    "        with torch.no_grad():\n",
    "            state = torch.tensor(np.array([state])).float().to(device)\n",
    "            action, pure_action, distr = self.actor.act(state)\n",
    "            prob = torch.exp(distr.log_prob(pure_action).sum(-1))\n",
    "        return action.cpu().numpy()[0], pure_action.cpu().numpy()[0], prob.cpu().item()\n",
    "    \n",
    "    def random_action(self):\n",
    "        return self.agent_id, [random.uniform(-1, 1) for _ in range(3)]\n",
    "\n",
    "    def save(self):\n",
    "        torch.save(self.actor, f\"agent_{self.agent_id}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eea09ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lambda_returns_and_gae(trajectory):\n",
    "    lambda_returns = []\n",
    "    gae = []\n",
    "    last_lr = 0.\n",
    "    last_v = 0.\n",
    "    for _, _, r, _, v in reversed(trajectory):\n",
    "        ret = r + GAMMA * (last_v * (1 - LAMBDA) + last_lr * LAMBDA)\n",
    "        last_lr = ret\n",
    "        last_v = v\n",
    "        lambda_returns.append(last_lr)\n",
    "        gae.append(last_lr - v)\n",
    "    return [(s, a, p, v, adv) for (s, a, _, p, _), v, adv in zip(trajectory, reversed(lambda_returns), reversed(gae))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "429b281e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_episode(env, agents):\n",
    "    observations = env.reset()\n",
    "    \n",
    "    dones = [False for _ in range(len(agents))]\n",
    "    \n",
    "    trajectories = [[] for _ in range(len(agents))]\n",
    "    k = 0\n",
    "\n",
    "    while not any(dones) and k < BATCH_SIZE:\n",
    "    \n",
    "        actions = []\n",
    "        pure_actions = []\n",
    "        probs = []\n",
    "        values = []\n",
    "        \n",
    "        for i in range(len(agents)):\n",
    "            a, pa, p = agents[i].act(observations[i])\n",
    "            actions.append((agents[i].agent_id, a))\n",
    "            pure_actions.append(pa)\n",
    "            probs.append(p)\n",
    "            \n",
    "            v = agents[i].get_value(observations[i])\n",
    "            values.append(v)\n",
    "\n",
    "        next_observations, rewards, dones, _, _ = env.step(actions)\n",
    "        \n",
    "        for i in range(len(agents)):\n",
    "            trajectories[i].append((observations[i], pure_actions[i], rewards[i], probs[i], values[i]))\n",
    "        \n",
    "        observations = next_observations\n",
    "        k += 1\n",
    "        \n",
    "    return [compute_lambda_returns_and_gae(trajectory) for trajectory in trajectories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ba3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy(env, agents, num_iter):\n",
    "    observations = env.reset()\n",
    "    result = []\n",
    "    dones = [False for _ in range(len(agents))]\n",
    "    k = 0\n",
    "\n",
    "    while not any(dones) and k < num_iter:\n",
    "        actions = []        \n",
    "        for i in range(len(agents)):\n",
    "            a, _, _ = agents[i].act(observations[i])\n",
    "            actions.append((agents[i].agent_id, a))\n",
    "        next_observations, rewards, dones, _, _ = env.step(actions)  \n",
    "        result.append(rewards)\n",
    "        observations = next_observations\n",
    "        k += 1\n",
    "        \n",
    "    return np.mean(result, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58ebeec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8cf4626a744e5dbd28eacdd1e806bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Богиня\\AppData\\Local\\Temp\\ipykernel_5068\\1992109076.py:42: UserWarning: Using a target size (torch.Size([32, 1, 1])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.smooth_l1_loss(value, target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50, Reward mean: 8.999979972839355, Reward std: 1.0191382898483425e-05\n",
      "Step: 100, Reward mean: 8.994186401367188, Reward std: 1.4854071196168661e-05\n",
      "Step: 150, Reward mean: 8.998918533325195, Reward std: 9.5367431640625e-07\n",
      "Step: 200, Reward mean: 8.999616622924805, Reward std: 0.0\n",
      "Step: 250, Reward mean: 8.999839782714844, Reward std: 0.0\n",
      "Step: 300, Reward mean: 8.999931335449219, Reward std: 1.2063131862305454e-06\n",
      "Step: 350, Reward mean: 8.999969482421875, Reward std: 0.0\n",
      "Step: 400, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 450, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 500, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 550, Reward mean: 8.999147415161133, Reward std: 2.523185003155959e-06\n",
      "Step: 600, Reward mean: 8.999847412109375, Reward std: 0.0\n",
      "Step: 650, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 700, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 750, Reward mean: 8.999728202819824, Reward std: 1.537753632874228e-06\n",
      "Step: 800, Reward mean: 8.999947547912598, Reward std: 0.0\n",
      "Step: 850, Reward mean: 8.999981880187988, Reward std: 0.0\n",
      "Step: 900, Reward mean: 8.999992370605469, Reward std: 0.0\n",
      "Step: 950, Reward mean: 8.999998092651367, Reward std: 0.0\n",
      "Step: 1000, Reward mean: 8.999998092651367, Reward std: 0.0\n",
      "Step: 1050, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1100, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1150, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1200, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1250, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1300, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1350, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1400, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1450, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1500, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1550, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1600, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 1650, Reward mean: 8.99842357635498, Reward std: 4.391046331875259e-06\n",
      "Step: 1700, Reward mean: 8.99958610534668, Reward std: 8.529922297384473e-07\n",
      "Step: 1750, Reward mean: 8.999871253967285, Reward std: 0.0\n",
      "Step: 1800, Reward mean: 8.999951362609863, Reward std: 0.0\n",
      "Step: 1850, Reward mean: 8.999979019165039, Reward std: 0.0\n",
      "Step: 1900, Reward mean: 8.999990463256836, Reward std: 0.0\n",
      "Step: 1950, Reward mean: 8.999994277954102, Reward std: 0.0\n",
      "Step: 2000, Reward mean: 8.999998092651367, Reward std: 0.0\n",
      "Step: 2050, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2100, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2150, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2200, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2250, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2300, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2350, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2400, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2450, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2500, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2550, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2600, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2650, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2700, Reward mean: 9.0, Reward std: 0.0\n",
      "Step: 2750, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 2800, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 2850, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 2900, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 2950, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3000, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3050, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3100, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3150, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3200, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3250, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3300, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3350, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3400, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3450, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3500, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3550, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3600, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3650, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3700, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3750, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3800, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3850, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3900, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 3950, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4000, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4050, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4100, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4150, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4200, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4250, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4300, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4350, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4400, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4450, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4500, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4550, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4600, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4650, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4700, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4750, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4800, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4850, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4900, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 4950, Reward mean: 7.333373069763184, Reward std: 0.0\n",
      "Step: 5000, Reward mean: 7.333373069763184, Reward std: 0.0\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "min_actives = 0\n",
    "max_actives = 10_000\n",
    "\n",
    "min_money = 500_000\n",
    "max_money = 1_000_000\n",
    "glass_len = 3\n",
    "state_dim = (glass_len * 2 + 3) * 2\n",
    "action_dim = 3\n",
    "num_agents = 10\n",
    "\n",
    "agents = [Agent(agent_id, random.randint(min_actives, max_actives), random.randint(min_money, max_money), state_dim, action_dim) for agent_id in range(num_agents)]\n",
    "env = MarketSimulation(agents, glass_len)\n",
    "\n",
    "for i in trange(ITERATIONS):\n",
    "        trajectories = sample_episode(env, agents)\n",
    "        \n",
    "        for agent, trajectory in zip(agents, trajectories):\n",
    "            agent.update(trajectory)\n",
    "\n",
    "        if (i + 1) % (ITERATIONS//100) == 0:\n",
    "            rewards = evaluate_policy(env, agents, 5)\n",
    "            print(f\"Step: {i+1}, Reward mean: {np.mean(rewards)}, Reward std: {np.std(rewards)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "315ca9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90b2e14eeee24206a2faae292e0d5d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Богиня\\AppData\\Local\\Temp\\ipykernel_7100\\514827332.py:42: UserWarning: Using a target size (torch.Size([16, 1, 1])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.smooth_l1_loss(value, target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 50, Reward mean: [[9.214831 ]\n",
      " [9.214831 ]\n",
      " [9.214831 ]\n",
      " [9.214831 ]\n",
      " [4.2148314]\n",
      " [9.214831 ]\n",
      " [9.214831 ]\n",
      " [9.214831 ]\n",
      " [9.214831 ]\n",
      " [9.214831 ]], Reward std: 1.5\n",
      "Step: 100, Reward mean: [[9.998097]\n",
      " [9.998097]\n",
      " [9.998097]\n",
      " [9.998097]\n",
      " [4.998097]\n",
      " [9.998097]\n",
      " [9.998097]\n",
      " [9.998097]\n",
      " [9.998097]\n",
      " [9.998097]], Reward std: 1.5000001192092896\n",
      "Step: 150, Reward mean: [[9.998495]\n",
      " [9.998495]\n",
      " [9.998495]\n",
      " [9.998495]\n",
      " [4.998495]\n",
      " [9.998495]\n",
      " [9.998495]\n",
      " [9.998495]\n",
      " [9.998495]\n",
      " [9.998495]], Reward std: 1.5\n",
      "Step: 200, Reward mean: [[9.999522]\n",
      " [9.999522]\n",
      " [9.999522]\n",
      " [9.999522]\n",
      " [4.999522]\n",
      " [9.999522]\n",
      " [9.999522]\n",
      " [9.999522]\n",
      " [9.999522]\n",
      " [9.999522]], Reward std: 1.5\n",
      "Step: 250, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 300, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 350, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 400, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 450, Reward mean: [[9.999995]\n",
      " [9.999995]\n",
      " [9.999995]\n",
      " [9.999995]\n",
      " [4.999995]\n",
      " [9.999995]\n",
      " [9.999995]\n",
      " [9.999995]\n",
      " [9.999995]\n",
      " [9.999995]], Reward std: 1.5\n",
      "Step: 500, Reward mean: [[9.999995 ]\n",
      " [9.999995 ]\n",
      " [9.999995 ]\n",
      " [9.999995 ]\n",
      " [4.9999948]\n",
      " [9.999995 ]\n",
      " [9.999995 ]\n",
      " [9.999995 ]\n",
      " [9.999995 ]\n",
      " [9.999995 ]], Reward std: 1.5000001192092896\n",
      "Step: 550, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 600, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 650, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 700, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 750, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 800, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 850, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 900, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 950, Reward mean: [[9.999708]\n",
      " [9.999708]\n",
      " [9.999708]\n",
      " [9.999708]\n",
      " [4.999708]\n",
      " [9.999708]\n",
      " [9.999708]\n",
      " [9.999708]\n",
      " [9.999708]\n",
      " [9.999708]], Reward std: 1.5\n",
      "Step: 1000, Reward mean: [[9.999879 ]\n",
      " [9.999879 ]\n",
      " [9.999879 ]\n",
      " [9.999879 ]\n",
      " [4.9998784]\n",
      " [9.999879 ]\n",
      " [9.999879 ]\n",
      " [9.999879 ]\n",
      " [9.999879 ]\n",
      " [9.999879 ]], Reward std: 1.5000001192092896\n",
      "Step: 1050, Reward mean: [[9.999932 ]\n",
      " [9.999932 ]\n",
      " [9.999932 ]\n",
      " [9.999932 ]\n",
      " [4.9999313]\n",
      " [9.999932 ]\n",
      " [9.999932 ]\n",
      " [9.999932 ]\n",
      " [9.999932 ]\n",
      " [9.999932 ]], Reward std: 1.5000003576278687\n",
      "Step: 1100, Reward mean: [[9.999956]\n",
      " [9.999956]\n",
      " [9.999956]\n",
      " [9.999956]\n",
      " [4.999956]\n",
      " [9.999956]\n",
      " [9.999956]\n",
      " [9.999956]\n",
      " [9.999956]\n",
      " [9.999956]], Reward std: 1.5\n",
      "Step: 1150, Reward mean: [[9.999944 ]\n",
      " [9.999944 ]\n",
      " [9.999944 ]\n",
      " [9.999944 ]\n",
      " [4.9999437]\n",
      " [9.999944 ]\n",
      " [9.999944 ]\n",
      " [9.999944 ]\n",
      " [9.999944 ]\n",
      " [9.999944 ]], Reward std: 1.5\n",
      "Step: 1200, Reward mean: [[9.999979 ]\n",
      " [9.999979 ]\n",
      " [9.999979 ]\n",
      " [9.999979 ]\n",
      " [4.9999785]\n",
      " [9.999979 ]\n",
      " [9.999979 ]\n",
      " [9.999979 ]\n",
      " [9.999979 ]\n",
      " [9.999979 ]], Reward std: 1.5000001192092896\n",
      "Step: 1250, Reward mean: [[ -9.905927]\n",
      " [ -9.905927]\n",
      " [ -9.905927]\n",
      " [ -9.905927]\n",
      " [-14.905927]\n",
      " [ -9.905927]\n",
      " [ -9.905927]\n",
      " [ -9.905927]\n",
      " [ -9.905927]\n",
      " [ -9.905927]], Reward std: 1.5\n",
      "Step: 1300, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1350, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1400, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1450, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1500, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1550, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1600, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1650, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1700, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1750, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1800, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1850, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1900, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 1950, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 2000, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 2050, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 2100, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 2150, Reward mean: [[10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [ 5.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]\n",
      " [10.]], Reward std: 1.5\n",
      "Step: 2200, Reward mean: [[9.990496]\n",
      " [9.990496]\n",
      " [9.990496]\n",
      " [9.990496]\n",
      " [4.990495]\n",
      " [9.990496]\n",
      " [9.990496]\n",
      " [9.990496]\n",
      " [9.990496]\n",
      " [9.990496]], Reward std: 1.5000001192092896\n",
      "Step: 2250, Reward mean: [[ 9.9985104e+00]\n",
      " [ 9.9985104e+00]\n",
      " [ 9.9985104e+00]\n",
      " [ 9.9985104e+00]\n",
      " [ 4.9985104e+00]\n",
      " [ 9.9985104e+00]\n",
      " [-1.1309825e-03]\n",
      " [ 9.9985104e+00]\n",
      " [ 9.9985104e+00]\n",
      " [ 9.9985104e+00]], Reward std: 3.2014670372009277\n",
      "Step: 2300, Reward mean: [[ 9.9993496e+00]\n",
      " [ 9.9993496e+00]\n",
      " [ 9.9993496e+00]\n",
      " [ 9.9993496e+00]\n",
      " [ 4.9993501e+00]\n",
      " [ 9.9993496e+00]\n",
      " [-2.9136776e-04]\n",
      " [ 9.9993496e+00]\n",
      " [ 9.9993496e+00]\n",
      " [ 9.9993496e+00]], Reward std: 3.2014670372009277\n",
      "Step: 2350, Reward mean: [[9.9997683e+00]\n",
      " [9.9997683e+00]\n",
      " [9.9997683e+00]\n",
      " [9.9997683e+00]\n",
      " [4.9997683e+00]\n",
      " [9.9997683e+00]\n",
      " [1.2672305e-04]\n",
      " [9.9997683e+00]\n",
      " [9.9997683e+00]\n",
      " [9.9997683e+00]], Reward std: 3.2014670372009277\n",
      "Step: 2400, Reward mean: [[9.9998274e+00]\n",
      " [9.9998274e+00]\n",
      " [9.9998274e+00]\n",
      " [9.9998274e+00]\n",
      " [4.9998274e+00]\n",
      " [9.9998274e+00]\n",
      " [1.8604159e-04]\n",
      " [9.9998274e+00]\n",
      " [9.9998274e+00]\n",
      " [9.9998274e+00]], Reward std: 3.2014667987823486\n",
      "Step: 2450, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 2500, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 2550, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 2600, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 2650, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 2700, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 2750, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 2800, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 2850, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 2900, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 2950, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3000, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3050, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3100, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3150, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3200, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3250, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3300, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3350, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3400, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3450, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3500, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3550, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3600, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 3650, Reward mean: [[9.9999943e+00]\n",
      " [9.9999943e+00]\n",
      " [9.9999943e+00]\n",
      " [9.9999943e+00]\n",
      " [4.9999948e+00]\n",
      " [9.9999943e+00]\n",
      " [3.5350682e-04]\n",
      " [9.9999943e+00]\n",
      " [9.9999943e+00]\n",
      " [9.9999943e+00]], Reward std: 3.2014665603637695\n",
      "Step: 3700, Reward mean: [[9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [4.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [3.5465122e-04]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]], Reward std: 3.2014670372009277\n",
      "Step: 3750, Reward mean: [[9.9999952e+00]\n",
      " [9.9999952e+00]\n",
      " [9.9999952e+00]\n",
      " [9.9999952e+00]\n",
      " [4.9999957e+00]\n",
      " [9.9999952e+00]\n",
      " [3.5465122e-04]\n",
      " [9.9999952e+00]\n",
      " [9.9999952e+00]\n",
      " [9.9999952e+00]], Reward std: 3.2014665603637695\n",
      "Step: 3800, Reward mean: [[9.9999952e+00]\n",
      " [9.9999952e+00]\n",
      " [9.9999952e+00]\n",
      " [9.9999952e+00]\n",
      " [4.9999957e+00]\n",
      " [9.9999952e+00]\n",
      " [3.5465122e-04]\n",
      " [9.9999952e+00]\n",
      " [9.9999952e+00]\n",
      " [9.9999952e+00]], Reward std: 3.2014665603637695\n",
      "Step: 3850, Reward mean: [[9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [4.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [3.5522343e-04]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]], Reward std: 3.2014670372009277\n",
      "Step: 3900, Reward mean: [[9.999995e+00]\n",
      " [9.999995e+00]\n",
      " [9.999995e+00]\n",
      " [9.999995e+00]\n",
      " [4.999995e+00]\n",
      " [9.999995e+00]\n",
      " [3.540790e-04]\n",
      " [9.999995e+00]\n",
      " [9.999995e+00]\n",
      " [9.999995e+00]], Reward std: 3.2014667987823486\n",
      "Step: 3950, Reward mean: [[9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [4.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [3.5522343e-04]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]], Reward std: 3.2014670372009277\n",
      "Step: 4000, Reward mean: [[9.9999943e+00]\n",
      " [9.9999943e+00]\n",
      " [9.9999943e+00]\n",
      " [9.9999943e+00]\n",
      " [4.9999948e+00]\n",
      " [9.9999943e+00]\n",
      " [3.5350682e-04]\n",
      " [9.9999943e+00]\n",
      " [9.9999943e+00]\n",
      " [9.9999943e+00]], Reward std: 3.2014665603637695\n",
      "Step: 4050, Reward mean: [[9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [4.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [3.5522343e-04]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]], Reward std: 3.2014670372009277\n",
      "Step: 4100, Reward mean: [[9.9999971e+00]\n",
      " [9.9999971e+00]\n",
      " [9.9999971e+00]\n",
      " [9.9999971e+00]\n",
      " [4.9999971e+00]\n",
      " [9.9999971e+00]\n",
      " [3.5579564e-04]\n",
      " [9.9999971e+00]\n",
      " [9.9999971e+00]\n",
      " [9.9999971e+00]], Reward std: 3.2014670372009277\n",
      "Step: 4150, Reward mean: [[9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [4.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [3.5465122e-04]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]\n",
      " [9.9999962e+00]], Reward std: 3.2014670372009277\n",
      "Step: 4200, Reward mean: [[9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [4.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [3.5694003e-04]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]], Reward std: 3.2014670372009277\n",
      "Step: 4250, Reward mean: [[9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [4.9999976e+00]\n",
      " [9.9999981e+00]\n",
      " [3.5636785e-04]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]], Reward std: 3.2014670372009277\n",
      "Step: 4300, Reward mean: [[9.9999971e+00]\n",
      " [9.9999971e+00]\n",
      " [9.9999971e+00]\n",
      " [9.9999971e+00]\n",
      " [4.9999971e+00]\n",
      " [9.9999971e+00]\n",
      " [3.5636785e-04]\n",
      " [9.9999971e+00]\n",
      " [9.9999971e+00]\n",
      " [9.9999971e+00]], Reward std: 3.2014667987823486\n",
      "Step: 4350, Reward mean: [[9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [4.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [3.5694003e-04]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]\n",
      " [9.9999981e+00]], Reward std: 3.2014670372009277\n",
      "Step: 4400, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [4.9999990e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5808445e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.201467275619507\n",
      "Step: 4450, Reward mean: [[9.999998e+00]\n",
      " [9.999998e+00]\n",
      " [9.999998e+00]\n",
      " [9.999998e+00]\n",
      " [4.999999e+00]\n",
      " [9.999998e+00]\n",
      " [3.577030e-04]\n",
      " [9.999998e+00]\n",
      " [9.999998e+00]\n",
      " [9.999998e+00]], Reward std: 3.2014665603637695\n",
      "Step: 4500, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [4.9999995e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5846591e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 4550, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 4600, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4650, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [4.9999995e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5846591e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 4700, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 4750, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 4800, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [4.9999995e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5846591e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 4850, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 4900, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 4950, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n",
      "Step: 5000, Reward mean: [[1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [5.0000000e+00]\n",
      " [1.0000000e+01]\n",
      " [3.5884738e-04]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]\n",
      " [1.0000000e+01]], Reward std: 3.2014670372009277\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "min_actives = 0\n",
    "max_actives = 10_000\n",
    "\n",
    "min_money = 500_000\n",
    "max_money = 1_000_000\n",
    "glass_len = 3\n",
    "state_dim = (glass_len * 2 + 3) * 2\n",
    "action_dim = 3\n",
    "num_agents = 10\n",
    "\n",
    "agents = [Agent(agent_id, random.randint(min_actives, max_actives), random.randint(min_money, max_money), state_dim, action_dim) for agent_id in range(num_agents)]\n",
    "env = MarketSimulation(agents, glass_len)\n",
    "\n",
    "for i in trange(ITERATIONS):\n",
    "        trajectories = sample_episode(env, agents)\n",
    "        \n",
    "        for agent, trajectory in zip(agents, trajectories):\n",
    "            agent.update(trajectory)\n",
    "\n",
    "        if (i + 1) % (ITERATIONS//100) == 0:\n",
    "            rewards = evaluate_policy(env, agents, 5)            \n",
    "            print(f\"Step: {i+1}, Reward mean: {rewards}, Reward std: {np.std(rewards)}\")\n",
    "            \n",
    "            for agent in agents:\n",
    "                agent.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68e86517",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdaf923400a41dfb62ded4fd34aa9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Богиня\\AppData\\Local\\Temp\\ipykernel_7784\\514827332.py:42: UserWarning: Using a target size (torch.Size([64, 1, 1])) that is different to the input size (torch.Size([64, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  critic_loss = F.smooth_l1_loss(value, target)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100, [[11.952913 ]\n",
      " [10.352913 ]\n",
      " [ 9.952913 ]\n",
      " [ 9.952913 ]\n",
      " [10.352913 ]\n",
      " [12.7529125]\n",
      " [10.7529125]\n",
      " [ 7.180186 ]], Reward mean: 10.406322479248047, Reward std: 1.5347384214401245\n",
      "Step: 200, [[ 7.8558607]\n",
      " [ 9.189194 ]\n",
      " [ 9.189194 ]\n",
      " [ 9.989194 ]\n",
      " [ 9.489194 ]\n",
      " [ 9.989194 ]\n",
      " [10.789194 ]\n",
      " [ 6.4164667]], Reward mean: 9.113436698913574, Reward std: 1.291795253753662\n",
      "Step: 300, [[ 7.1046066]\n",
      " [ 9.993495 ]\n",
      " [ 9.993495 ]\n",
      " [ 9.993495 ]\n",
      " [ 7.8434954]\n",
      " [11.193495 ]\n",
      " [ 9.993495 ]\n",
      " [ 7.220768 ]], Reward mean: 9.167043685913086, Reward std: 1.4418740272521973\n",
      "Step: 400, [[ 7.104673 ]\n",
      " [ 9.993563 ]\n",
      " [ 9.993563 ]\n",
      " [ 9.993563 ]\n",
      " [ 7.493562 ]\n",
      " [10.793562 ]\n",
      " [ 9.993563 ]\n",
      " [ 7.2208343]], Reward mean: 9.073360443115234, Reward std: 1.4208065271377563\n",
      "Step: 500, [[ 7.0947685]\n",
      " [ 9.983658 ]\n",
      " [ 9.983658 ]\n",
      " [10.383657 ]\n",
      " [ 9.483658 ]\n",
      " [11.983658 ]\n",
      " [ 9.983658 ]\n",
      " [ 7.21093  ]], Reward mean: 9.513455390930176, Reward std: 1.5278652906417847\n",
      "Step: 600, [[ 7.0936823]\n",
      " [ 9.982572 ]\n",
      " [ 9.982572 ]\n",
      " [ 9.982572 ]\n",
      " [ 9.482572 ]\n",
      " [11.982572 ]\n",
      " [ 9.982572 ]\n",
      " [ 7.2098436]], Reward mean: 9.462369918823242, Reward std: 1.5049426555633545\n",
      "Step: 700, [[ 7.104567 ]\n",
      " [ 9.993456 ]\n",
      " [ 9.993456 ]\n",
      " [ 9.993456 ]\n",
      " [ 9.493456 ]\n",
      " [11.993456 ]\n",
      " [ 9.993456 ]\n",
      " [ 7.2207284]], Reward mean: 9.47325325012207, Reward std: 1.5049424171447754\n",
      "Step: 800, [[ 7.0932107]\n",
      " [ 9.9821   ]\n",
      " [ 9.9821   ]\n",
      " [ 9.9821   ]\n",
      " [ 9.4821   ]\n",
      " [11.982099 ]\n",
      " [ 9.9821   ]\n",
      " [ 7.209372 ]], Reward mean: 9.461896896362305, Reward std: 1.5049422979354858\n",
      "Step: 900, [[ 7.097918 ]\n",
      " [ 9.986807 ]\n",
      " [ 9.986807 ]\n",
      " [ 9.986807 ]\n",
      " [ 9.486807 ]\n",
      " [11.986807 ]\n",
      " [ 9.986807 ]\n",
      " [ 7.2140794]], Reward mean: 9.466604232788086, Reward std: 1.5049424171447754\n",
      "Step: 1000, [[ 7.1073694]\n",
      " [ 9.996259 ]\n",
      " [ 9.996259 ]\n",
      " [ 9.996259 ]\n",
      " [ 9.496259 ]\n",
      " [11.996259 ]\n",
      " [ 9.996259 ]\n",
      " [ 7.223531 ]], Reward mean: 9.476057052612305, Reward std: 1.5049426555633545\n",
      "Step: 1100, [[ 7.1003885]\n",
      " [ 9.989277 ]\n",
      " [ 9.989277 ]\n",
      " [ 9.989277 ]\n",
      " [ 9.489277 ]\n",
      " [11.989277 ]\n",
      " [ 9.989277 ]\n",
      " [ 7.21655  ]], Reward mean: 9.469074249267578, Reward std: 1.5049422979354858\n",
      "Step: 1200, [[ 7.1108003]\n",
      " [10.799688 ]\n",
      " [ 9.999689 ]\n",
      " [ 9.999689 ]\n",
      " [ 9.499689 ]\n",
      " [11.999689 ]\n",
      " [ 9.999689 ]\n",
      " [ 7.2269616]], Reward mean: 9.579486846923828, Reward std: 1.5616952180862427\n",
      "Step: 1300, [[ 7.11099  ]\n",
      " [10.399879 ]\n",
      " [ 9.99988  ]\n",
      " [ 9.99988  ]\n",
      " [ 9.49988  ]\n",
      " [11.99988  ]\n",
      " [ 9.99988  ]\n",
      " [ 7.2271514]], Reward mean: 9.529677391052246, Reward std: 1.5278655290603638\n",
      "Step: 1400, [[ 7.110317 ]\n",
      " [11.199205 ]\n",
      " [ 9.999206 ]\n",
      " [ 9.999206 ]\n",
      " [ 9.499206 ]\n",
      " [11.999206 ]\n",
      " [ 9.999206 ]\n",
      " [ 7.2264786]], Reward mean: 9.629003524780273, Reward std: 1.605743408203125\n",
      "Step: 1500, [[ 7.1098356]\n",
      " [11.998724 ]\n",
      " [ 9.998724 ]\n",
      " [ 9.998724 ]\n",
      " [ 9.498724 ]\n",
      " [11.998724 ]\n",
      " [ 9.998724 ]\n",
      " [ 7.225997 ]], Reward mean: 9.728521347045898, Reward std: 1.721177577972412\n",
      "Step: 1600, [[ 7.1110916]\n",
      " [11.99998  ]\n",
      " [ 9.99998  ]\n",
      " [ 9.99998  ]\n",
      " [ 9.49998  ]\n",
      " [11.99998  ]\n",
      " [ 9.99998  ]\n",
      " [ 7.227253 ]], Reward mean: 9.729778289794922, Reward std: 1.721177577972412\n",
      "Step: 1700, [[ 7.111093 ]\n",
      " [11.999982 ]\n",
      " [ 9.999982 ]\n",
      " [ 9.999982 ]\n",
      " [ 9.499982 ]\n",
      " [11.999982 ]\n",
      " [ 9.999982 ]\n",
      " [ 7.2272544]], Reward mean: 9.729780197143555, Reward std: 1.7211778163909912\n",
      "Step: 1800, [[ 7.1098657]\n",
      " [ 9.9987545]\n",
      " [ 9.9987545]\n",
      " [ 9.9987545]\n",
      " [ 9.4987545]\n",
      " [11.9987545]\n",
      " [ 9.9987545]\n",
      " [ 7.226027 ]], Reward mean: 9.478551864624023, Reward std: 1.5049424171447754\n",
      "Step: 1900, [[ 7.1109796]\n",
      " [11.999868 ]\n",
      " [ 9.999868 ]\n",
      " [ 9.999868 ]\n",
      " [ 9.499868 ]\n",
      " [11.999868 ]\n",
      " [ 9.999868 ]\n",
      " [ 7.227141 ]], Reward mean: 9.729665756225586, Reward std: 1.7211778163909912\n",
      "Step: 2000, [[ 7.110994]\n",
      " [11.999883]\n",
      " [ 9.999883]\n",
      " [ 9.999883]\n",
      " [ 9.499883]\n",
      " [11.999883]\n",
      " [ 9.999883]\n",
      " [ 7.227155]], Reward mean: 9.729681015014648, Reward std: 1.7211778163909912\n",
      "Step: 2100, [[ 7.105826 ]\n",
      " [11.994715 ]\n",
      " [ 9.994715 ]\n",
      " [ 9.994715 ]\n",
      " [ 9.094714 ]\n",
      " [11.994715 ]\n",
      " [ 9.994715 ]\n",
      " [ 7.2219872]], Reward mean: 9.67451286315918, Reward std: 1.732897162437439\n",
      "Step: 2200, [[ 7.110832 ]\n",
      " [ 9.999721 ]\n",
      " [ 9.999721 ]\n",
      " [ 9.999721 ]\n",
      " [ 6.666388 ]\n",
      " [ 9.999721 ]\n",
      " [10.799721 ]\n",
      " [ 7.2269936]], Reward mean: 8.97535228729248, Reward std: 1.556845784187317\n",
      "Step: 2300, [[ 7.1111116]\n",
      " [10.       ]\n",
      " [10.       ]\n",
      " [10.       ]\n",
      " [ 7.466667 ]\n",
      " [10.       ]\n",
      " [10.       ]\n",
      " [ 7.227273 ]], Reward mean: 8.975631713867188, Reward std: 1.3255573511123657\n",
      "Step: 2400, [[ 5.0786824]\n",
      " [ 9.967571 ]\n",
      " [ 9.967571 ]\n",
      " [ 9.967571 ]\n",
      " [ 9.034238 ]\n",
      " [ 9.967571 ]\n",
      " [11.967571 ]\n",
      " [ 6.794843 ]], Reward mean: 9.093202590942383, Reward std: 2.0224485397338867\n",
      "Step: 2500, [[ 5.1100736]\n",
      " [ 9.998962 ]\n",
      " [ 9.998962 ]\n",
      " [ 9.998962 ]\n",
      " [ 6.665629 ]\n",
      " [ 9.998962 ]\n",
      " [11.998962 ]\n",
      " [ 5.226235 ]], Reward mean: 8.624593734741211, Reward std: 2.415578603744507\n",
      "Step: 2600, [[5.1078224]\n",
      " [9.996711 ]\n",
      " [9.996711 ]\n",
      " [9.996711 ]\n",
      " [8.263378 ]\n",
      " [9.996711 ]\n",
      " [9.996711 ]\n",
      " [7.223984 ]], Reward mean: 8.822341918945312, Reward std: 1.7161204814910889\n",
      "Step: 2700, [[ 5.5015345]\n",
      " [ 9.990423 ]\n",
      " [ 9.990423 ]\n",
      " [ 9.990423 ]\n",
      " [ 9.45709  ]\n",
      " [10.390424 ]\n",
      " [11.990423 ]\n",
      " [ 7.217696 ]], Reward mean: 9.316055297851562, Reward std: 1.8922340869903564\n",
      "Step: 2800, [[ 5.110816 ]\n",
      " [ 9.999704 ]\n",
      " [ 9.999704 ]\n",
      " [ 9.999704 ]\n",
      " [ 9.999704 ]\n",
      " [ 9.999704 ]\n",
      " [11.999705 ]\n",
      " [ 7.2269773]], Reward mean: 9.292001724243164, Reward std: 1.9869107007980347\n",
      "Step: 2900, [[ 5.1104383]\n",
      " [ 9.999327 ]\n",
      " [ 9.999327 ]\n",
      " [ 9.999327 ]\n",
      " [ 9.999327 ]\n",
      " [ 9.999327 ]\n",
      " [11.999327 ]\n",
      " [ 7.2265997]], Reward mean: 9.291624069213867, Reward std: 1.9869105815887451\n",
      "Step: 3000, [[ 5.1111097]\n",
      " [ 9.999998 ]\n",
      " [ 9.999998 ]\n",
      " [ 9.999998 ]\n",
      " [ 9.999998 ]\n",
      " [ 9.999998 ]\n",
      " [11.999998 ]\n",
      " [ 7.227271 ]], Reward mean: 9.292295455932617, Reward std: 1.9869105815887451\n",
      "Step: 3100, [[5.111104 ]\n",
      " [9.999992 ]\n",
      " [9.999992 ]\n",
      " [9.999992 ]\n",
      " [9.999992 ]\n",
      " [9.999992 ]\n",
      " [9.999992 ]\n",
      " [7.2272654]], Reward mean: 9.042289733886719, Reward std: 1.7411094903945923\n",
      "Step: 3200, [[ 5.1101213]\n",
      " [ 9.99901  ]\n",
      " [ 9.99901  ]\n",
      " [ 9.99901  ]\n",
      " [ 9.99901  ]\n",
      " [ 9.99901  ]\n",
      " [12.39901  ]\n",
      " [ 7.2262826]], Reward mean: 9.34130859375, Reward std: 2.0581748485565186\n",
      "Step: 3300, [[ 5.1111045]\n",
      " [ 9.999993 ]\n",
      " [ 9.999993 ]\n",
      " [ 9.999993 ]\n",
      " [ 9.999993 ]\n",
      " [ 9.999993 ]\n",
      " [13.999994 ]\n",
      " [ 7.227266 ]], Reward mean: 9.542291641235352, Reward std: 2.395655632019043\n",
      "Step: 3400, [[ 5.1109786]\n",
      " [ 9.999867 ]\n",
      " [ 9.999867 ]\n",
      " [ 9.999867 ]\n",
      " [ 9.999867 ]\n",
      " [ 9.999867 ]\n",
      " [13.199867 ]\n",
      " [ 7.22714  ]], Reward mean: 9.44216537475586, Reward std: 2.21757173538208\n",
      "Step: 3500, [[5.1110015]\n",
      " [9.999891 ]\n",
      " [9.999891 ]\n",
      " [9.999891 ]\n",
      " [9.999891 ]\n",
      " [9.999891 ]\n",
      " [9.999891 ]\n",
      " [7.227163 ]], Reward mean: 9.04218864440918, Reward std: 1.7411102056503296\n",
      "Step: 3600, [[ 5.1109495]\n",
      " [ 9.999838 ]\n",
      " [ 9.999838 ]\n",
      " [ 9.999838 ]\n",
      " [ 9.999838 ]\n",
      " [10.3998375]\n",
      " [ 9.999838 ]\n",
      " [ 7.2271104]], Reward mean: 9.09213638305664, Reward std: 1.7733395099639893\n",
      "Step: 3700, [[ 5.1111026]\n",
      " [ 9.999991 ]\n",
      " [ 9.999991 ]\n",
      " [12.799992 ]\n",
      " [ 9.999991 ]\n",
      " [11.999991 ]\n",
      " [ 9.999991 ]\n",
      " [ 7.2272644]], Reward mean: 9.642290115356445, Reward std: 2.302326202392578\n",
      "Step: 3800, [[ 5.110361]\n",
      " [ 9.99925 ]\n",
      " [ 9.99925 ]\n",
      " [11.99925 ]\n",
      " [ 9.99925 ]\n",
      " [10.79925 ]\n",
      " [ 9.99925 ]\n",
      " [ 7.226522]], Reward mean: 9.391548156738281, Reward std: 2.039449691772461\n",
      "Step: 3900, [[ 5.1107755]\n",
      " [ 9.999664 ]\n",
      " [ 9.999664 ]\n",
      " [11.999664 ]\n",
      " [ 9.999664 ]\n",
      " [11.999664 ]\n",
      " [ 9.999664 ]\n",
      " [ 7.2269373]], Reward mean: 9.541961669921875, Reward std: 2.176962375640869\n",
      "Step: 4000, [[ 5.110442 ]\n",
      " [ 9.999331 ]\n",
      " [ 9.999331 ]\n",
      " [ 9.999331 ]\n",
      " [ 9.999331 ]\n",
      " [11.999331 ]\n",
      " [ 9.999331 ]\n",
      " [ 7.2266035]], Reward mean: 9.291629791259766, Reward std: 1.9869109392166138\n",
      "Step: 4100, [[ 5.1110888]\n",
      " [ 9.999978 ]\n",
      " [ 9.999978 ]\n",
      " [ 9.999978 ]\n",
      " [ 9.999978 ]\n",
      " [ 9.999978 ]\n",
      " [11.5999775]\n",
      " [ 7.2272506]], Reward mean: 9.242276191711426, Reward std: 1.9221197366714478\n",
      "Step: 4200, [[ 5.1104937]\n",
      " [ 9.999382 ]\n",
      " [ 9.999382 ]\n",
      " [11.999382 ]\n",
      " [ 9.999382 ]\n",
      " [11.999382 ]\n",
      " [ 9.999382 ]\n",
      " [ 6.826655 ]], Reward mean: 9.491680145263672, Reward std: 2.2334203720092773\n",
      "Step: 4300, [[ 5.111082]\n",
      " [ 9.999971]\n",
      " [ 9.999971]\n",
      " [ 9.999971]\n",
      " [ 9.999971]\n",
      " [10.799971]\n",
      " [ 9.999971]\n",
      " [ 7.227243]], Reward mean: 9.142269134521484, Reward std: 1.8146636486053467\n",
      "Step: 4400, [[ 5.106238]\n",
      " [ 9.995127]\n",
      " [ 9.995127]\n",
      " [11.995127]\n",
      " [ 9.995127]\n",
      " [11.595126]\n",
      " [ 9.995127]\n",
      " [ 6.822399]], Reward mean: 9.437423706054688, Reward std: 2.180572748184204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 4500, [[ 5.110299 ]\n",
      " [ 9.999188 ]\n",
      " [ 9.999188 ]\n",
      " [13.999188 ]\n",
      " [ 9.999188 ]\n",
      " [ 9.999188 ]\n",
      " [ 9.999188 ]\n",
      " [ 6.0264606]], Reward mean: 9.391486167907715, Reward std: 2.5673282146453857\n",
      "Step: 4600, [[ 5.110895]\n",
      " [ 9.999784]\n",
      " [ 9.999784]\n",
      " [11.999784]\n",
      " [ 9.999784]\n",
      " [10.799784]\n",
      " [10.399784]\n",
      " [ 6.827056]], Reward mean: 9.392082214355469, Reward std: 2.115804433822632\n",
      "Step: 4700, [[ 5.111091 ]\n",
      " [ 9.99998  ]\n",
      " [ 9.99998  ]\n",
      " [ 9.99998  ]\n",
      " [ 9.99998  ]\n",
      " [ 9.99998  ]\n",
      " [10.399981 ]\n",
      " [ 6.0272527]], Reward mean: 8.942277908325195, Reward std: 1.9651312828063965\n",
      "Step: 4800, [[ 5.058069]\n",
      " [ 9.946958]\n",
      " [ 9.946958]\n",
      " [11.146957]\n",
      " [ 9.946958]\n",
      " [11.146957]\n",
      " [11.146957]\n",
      " [ 5.974231]], Reward mean: 9.289255142211914, Reward std: 2.251199960708618\n",
      "Step: 4900, [[ 5.111061 ]\n",
      " [ 9.999949 ]\n",
      " [ 9.999949 ]\n",
      " [11.999949 ]\n",
      " [ 9.999949 ]\n",
      " [11.59995  ]\n",
      " [11.199949 ]\n",
      " [ 5.6272225]], Reward mean: 9.44224739074707, Reward std: 2.4630701541900635\n",
      "Step: 5000, [[ 5.1111097]\n",
      " [ 9.999999 ]\n",
      " [ 9.999999 ]\n",
      " [ 9.999999 ]\n",
      " [ 9.999999 ]\n",
      " [11.999999 ]\n",
      " [11.199999 ]\n",
      " [ 5.227271 ]], Reward mean: 9.192296981811523, Reward std: 2.42128849029541\n",
      "Step: 5100, [[ 5.111079 ]\n",
      " [ 9.999968 ]\n",
      " [ 9.999968 ]\n",
      " [ 9.999968 ]\n",
      " [ 9.999968 ]\n",
      " [11.999968 ]\n",
      " [11.599968 ]\n",
      " [ 5.2272406]], Reward mean: 9.242265701293945, Reward std: 2.465949535369873\n",
      "Step: 5200, [[ 5.109158 ]\n",
      " [ 9.998047 ]\n",
      " [ 9.998047 ]\n",
      " [10.798047 ]\n",
      " [ 9.998047 ]\n",
      " [ 9.998047 ]\n",
      " [11.598047 ]\n",
      " [ 5.2253194]], Reward mean: 9.090344429016113, Reward std: 2.326176643371582\n",
      "Step: 5300, [[ 5.110851]\n",
      " [ 9.99974 ]\n",
      " [ 9.99974 ]\n",
      " [11.99974 ]\n",
      " [ 9.99974 ]\n",
      " [11.59974 ]\n",
      " [11.199739]\n",
      " [ 5.227012]], Reward mean: 9.392037391662598, Reward std: 2.5427777767181396\n",
      "Step: 5400, [[ 5.11107  ]\n",
      " [ 9.999959 ]\n",
      " [ 9.999959 ]\n",
      " [12.79996  ]\n",
      " [ 9.999959 ]\n",
      " [11.199961 ]\n",
      " [11.59996  ]\n",
      " [ 5.2272315]], Reward mean: 9.492258071899414, Reward std: 2.656550645828247\n",
      "Step: 5500, [[ 5.111061 ]\n",
      " [ 9.999949 ]\n",
      " [ 9.999949 ]\n",
      " [ 9.999949 ]\n",
      " [ 9.999949 ]\n",
      " [11.999949 ]\n",
      " [11.999949 ]\n",
      " [ 5.2272224]], Reward mean: 9.292247772216797, Reward std: 2.5167791843414307\n",
      "Step: 5600, [[ 5.1110663]\n",
      " [ 9.999956 ]\n",
      " [ 9.999956 ]\n",
      " [13.199956 ]\n",
      " [ 9.999956 ]\n",
      " [10.399956 ]\n",
      " [10.399956 ]\n",
      " [ 5.2272277]], Reward mean: 9.292253494262695, Reward std: 2.5795695781707764\n",
      "Step: 5700, [[ 5.1110783]\n",
      " [ 9.999967 ]\n",
      " [ 9.999967 ]\n",
      " [13.999967 ]\n",
      " [ 9.999967 ]\n",
      " [11.199966 ]\n",
      " [10.799967 ]\n",
      " [ 5.2272396]], Reward mean: 9.542264938354492, Reward std: 2.8081183433532715\n",
      "Step: 5800, [[ 5.1111064]\n",
      " [ 9.999995 ]\n",
      " [ 9.999995 ]\n",
      " [12.799995 ]\n",
      " [ 9.999995 ]\n",
      " [ 9.999995 ]\n",
      " [10.799995 ]\n",
      " [ 5.2272677]], Reward mean: 9.242293357849121, Reward std: 2.51414155960083\n",
      "Step: 5900, [[ 5.1110234]\n",
      " [ 9.999912 ]\n",
      " [ 9.999912 ]\n",
      " [13.199911 ]\n",
      " [ 9.999912 ]\n",
      " [ 9.999912 ]\n",
      " [11.599912 ]\n",
      " [ 5.227185 ]], Reward mean: 9.392210006713867, Reward std: 2.658141613006592\n",
      "Step: 6000, [[ 5.111104 ]\n",
      " [ 9.999992 ]\n",
      " [ 9.999992 ]\n",
      " [12.399992 ]\n",
      " [ 9.999992 ]\n",
      " [ 9.999992 ]\n",
      " [ 9.999992 ]\n",
      " [ 5.2272654]], Reward mean: 9.092290878295898, Reward std: 2.3939707279205322\n",
      "Step: 6100, [[ 5.1111   ]\n",
      " [ 9.9999895]\n",
      " [ 9.9999895]\n",
      " [11.9999895]\n",
      " [ 9.9999895]\n",
      " [ 9.9999895]\n",
      " [ 9.9999895]\n",
      " [ 5.2272615]], Reward mean: 9.042287826538086, Reward std: 2.327622890472412\n",
      "Step: 6200, [[ 5.1110864]\n",
      " [ 9.999975 ]\n",
      " [ 9.999975 ]\n",
      " [13.599976 ]\n",
      " [ 9.999975 ]\n",
      " [ 9.999975 ]\n",
      " [10.799975 ]\n",
      " [ 5.2272477]], Reward mean: 9.342273712158203, Reward std: 2.665041923522949\n",
      "Step: 6300, [[ 5.11097  ]\n",
      " [ 9.99986  ]\n",
      " [ 9.99986  ]\n",
      " [12.79986  ]\n",
      " [ 9.99986  ]\n",
      " [ 9.99986  ]\n",
      " [ 9.99986  ]\n",
      " [ 5.2271314]], Reward mean: 9.142158508300781, Reward std: 2.465637683868408\n",
      "Step: 6400, [[ 5.1110907]\n",
      " [ 9.999979 ]\n",
      " [ 9.999979 ]\n",
      " [14.399979 ]\n",
      " [ 9.999979 ]\n",
      " [ 9.999979 ]\n",
      " [ 9.999979 ]\n",
      " [ 5.227252 ]], Reward mean: 9.342277526855469, Reward std: 2.7968637943267822\n",
      "Step: 6500, [[ 5.111105 ]\n",
      " [ 9.999994 ]\n",
      " [ 9.999994 ]\n",
      " [11.999994 ]\n",
      " [ 9.999994 ]\n",
      " [ 9.999994 ]\n",
      " [10.7999935]\n",
      " [ 5.2272663]], Reward mean: 9.142292022705078, Reward std: 2.3831424713134766\n",
      "Step: 6600, [[ 5.11111  ]\n",
      " [ 9.999999 ]\n",
      " [ 9.999999 ]\n",
      " [13.2      ]\n",
      " [ 9.999999 ]\n",
      " [ 9.999999 ]\n",
      " [10.4      ]\n",
      " [ 5.2272716]], Reward mean: 9.242297172546387, Reward std: 2.561427116394043\n",
      "Step: 6700, [[ 5.1111107]\n",
      " [10.       ]\n",
      " [10.       ]\n",
      " [14.       ]\n",
      " [10.       ]\n",
      " [10.       ]\n",
      " [10.4      ]\n",
      " [ 5.227272 ]], Reward mean: 9.34229850769043, Reward std: 2.724417209625244\n",
      "Step: 6800, [[ 5.1111073]\n",
      " [ 9.999996 ]\n",
      " [ 9.999996 ]\n",
      " [12.399996 ]\n",
      " [ 9.999996 ]\n",
      " [ 9.999996 ]\n",
      " [ 9.999996 ]\n",
      " [ 5.2272687]], Reward mean: 9.092293739318848, Reward std: 2.3939709663391113\n",
      "Step: 6900, [[ 5.1111073]\n",
      " [ 9.999997 ]\n",
      " [ 9.999997 ]\n",
      " [12.799997 ]\n",
      " [ 9.999997 ]\n",
      " [ 9.999997 ]\n",
      " [ 9.999997 ]\n",
      " [ 5.2272687]], Reward mean: 9.142295837402344, Reward std: 2.465637683868408\n",
      "Step: 7000, [[ 5.1111093]\n",
      " [10.799998 ]\n",
      " [ 9.999998 ]\n",
      " [12.399999 ]\n",
      " [ 9.999998 ]\n",
      " [ 9.999998 ]\n",
      " [10.399999 ]\n",
      " [ 5.2272706]], Reward mean: 9.24229621887207, Reward std: 2.465949773788452\n",
      "Step: 7100, [[ 5.111111 ]\n",
      " [10.       ]\n",
      " [10.       ]\n",
      " [12.       ]\n",
      " [10.       ]\n",
      " [10.4      ]\n",
      " [10.       ]\n",
      " [ 5.2272725]], Reward mean: 9.09229850769043, Reward std: 2.3518285751342773\n",
      "Step: 7200, [[ 5.1111107]\n",
      " [10.       ]\n",
      " [10.       ]\n",
      " [12.4      ]\n",
      " [10.       ]\n",
      " [11.2      ]\n",
      " [14.       ]\n",
      " [ 5.227272 ]], Reward mean: 9.742298126220703, Reward std: 2.9442503452301025\n",
      "Step: 7300, [[ 5.0044093]\n",
      " [11.6      ]\n",
      " [10.       ]\n",
      " [10.       ]\n",
      " [10.       ]\n",
      " [10.       ]\n",
      " [ 7.5      ]\n",
      " [ 5.2272725]], Reward mean: 8.666460037231445, Reward std: 2.2999517917633057\n",
      "Step: 7400, [[ 5.004406]\n",
      " [10.799997]\n",
      " [ 9.999997]\n",
      " [ 9.999997]\n",
      " [ 9.999997]\n",
      " [ 9.999997]\n",
      " [ 7.499997]\n",
      " [ 5.227269]], Reward mean: 8.566457748413086, Reward std: 2.1847360134124756\n",
      "Step: 7500, [[ 5.0040455]\n",
      " [10.399636 ]\n",
      " [ 9.999636 ]\n",
      " [11.999636 ]\n",
      " [ 9.999636 ]\n",
      " [11.999636 ]\n",
      " [ 7.499636 ]\n",
      " [ 5.2269087]], Reward mean: 9.016096115112305, Reward std: 2.607825756072998\n",
      "Step: 7600, [[ 5.0042753]\n",
      " [ 9.999866 ]\n",
      " [ 9.999866 ]\n",
      " [11.999866 ]\n",
      " [ 9.999866 ]\n",
      " [ 9.999866 ]\n",
      " [13.599866 ]\n",
      " [ 5.2271385]], Reward mean: 9.478826522827148, Reward std: 2.7955989837646484\n",
      "Step: 7700, [[ 4.858853 ]\n",
      " [10.654444 ]\n",
      " [ 9.854444 ]\n",
      " [11.854444 ]\n",
      " [ 9.854444 ]\n",
      " [ 9.854444 ]\n",
      " [11.454443 ]\n",
      " [ 5.0817156]], Reward mean: 9.183403968811035, Reward std: 2.5330934524536133\n",
      "Step: 7800, [[ 5.0043116]\n",
      " [11.999902 ]\n",
      " [ 9.999902 ]\n",
      " [13.199903 ]\n",
      " [ 9.999902 ]\n",
      " [ 9.999902 ]\n",
      " [ 9.999902 ]\n",
      " [ 5.227174 ]], Reward mean: 9.428861618041992, Reward std: 2.724109172821045\n",
      "Step: 7900, [[ 3.6959033]\n",
      " [10.291494 ]\n",
      " [ 8.691494 ]\n",
      " [11.891494 ]\n",
      " [ 8.691494 ]\n",
      " [ 8.691494 ]\n",
      " [ 8.691494 ]\n",
      " [ 3.9187665]], Reward mean: 8.070454597473145, Reward std: 2.679769992828369\n",
      "Step: 8000, [[ 5.0042543]\n",
      " [11.9998455]\n",
      " [ 9.9998455]\n",
      " [15.199844 ]\n",
      " [ 9.9998455]\n",
      " [ 9.9998455]\n",
      " [ 9.9998455]\n",
      " [ 5.2271175]], Reward mean: 9.678805351257324, Reward std: 3.121504306793213\n",
      "Step: 8100, [[ 5.0043597]\n",
      " [11.999951 ]\n",
      " [ 9.99995  ]\n",
      " [13.199951 ]\n",
      " [ 9.99995  ]\n",
      " [ 9.99995  ]\n",
      " [ 9.99995  ]\n",
      " [ 5.227223 ]], Reward mean: 9.428911209106445, Reward std: 2.724109411239624\n",
      "Step: 8200, [[ 5.00439 ]\n",
      " [11.59998 ]\n",
      " [ 9.99998 ]\n",
      " [15.19998 ]\n",
      " [ 9.99998 ]\n",
      " [ 9.99998 ]\n",
      " [ 9.99998 ]\n",
      " [ 5.227253]], Reward mean: 9.62894058227539, Reward std: 3.08693790435791\n",
      "Step: 8300, [[ 5.0043263]\n",
      " [11.999918 ]\n",
      " [ 9.999918 ]\n",
      " [ 9.999918 ]\n",
      " [ 9.999918 ]\n",
      " [ 9.999918 ]\n",
      " [ 9.999918 ]\n",
      " [ 5.227189 ]], Reward mean: 9.028878211975098, Reward std: 2.350306510925293\n",
      "Step: 8400, [[ 5.0043106]\n",
      " [11.999901 ]\n",
      " [ 9.999901 ]\n",
      " [ 9.999901 ]\n",
      " [ 9.999901 ]\n",
      " [ 9.999901 ]\n",
      " [ 9.999901 ]\n",
      " [ 5.227174 ]], Reward mean: 9.028861045837402, Reward std: 2.3503057956695557\n",
      "Step: 8500, [[ 5.004403 ]\n",
      " [11.999994 ]\n",
      " [ 9.999994 ]\n",
      " [ 9.999994 ]\n",
      " [ 9.999994 ]\n",
      " [ 9.999994 ]\n",
      " [ 9.999994 ]\n",
      " [ 5.2272663]], Reward mean: 9.02895450592041, Reward std: 2.350306272506714\n",
      "Step: 8600, [[ 5.0042615]\n",
      " [11.999852 ]\n",
      " [ 9.999852 ]\n",
      " [ 9.999852 ]\n",
      " [ 9.999852 ]\n",
      " [ 9.999852 ]\n",
      " [ 9.999852 ]\n",
      " [ 5.227124 ]], Reward mean: 9.028812408447266, Reward std: 2.3503060340881348\n",
      "Step: 8700, [[ 5.004379 ]\n",
      " [11.9999695]\n",
      " [ 9.9999695]\n",
      " [ 9.9999695]\n",
      " [ 9.9999695]\n",
      " [ 9.9999695]\n",
      " [ 9.9999695]\n",
      " [ 5.227242 ]], Reward mean: 9.028929710388184, Reward std: 2.3503060340881348\n",
      "Step: 8800, [[ 5.0039206]\n",
      " [11.999512 ]\n",
      " [ 9.999512 ]\n",
      " [ 9.999512 ]\n",
      " [ 9.999512 ]\n",
      " [ 9.999512 ]\n",
      " [ 9.999512 ]\n",
      " [ 5.226784 ]], Reward mean: 9.028471946716309, Reward std: 2.3503060340881348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 8900, [[ 5.0043955]\n",
      " [11.999987 ]\n",
      " [ 9.999987 ]\n",
      " [ 9.999987 ]\n",
      " [ 9.999987 ]\n",
      " [ 9.999987 ]\n",
      " [ 9.999987 ]\n",
      " [ 5.227259 ]], Reward mean: 9.028946876525879, Reward std: 2.3503060340881348\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m env \u001b[38;5;241m=\u001b[39m MarketSimulation(agents, glass_len)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(ITERATIONS):\n\u001b[1;32m---> 17\u001b[0m         trajectories \u001b[38;5;241m=\u001b[39m \u001b[43msample_episode\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m agent, trajectory \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(agents, trajectories):\n\u001b[0;32m     20\u001b[0m             agent\u001b[38;5;241m.\u001b[39mupdate(trajectory)\n",
      "Cell \u001b[1;32mIn[5], line 22\u001b[0m, in \u001b[0;36msample_episode\u001b[1;34m(env, agents)\u001b[0m\n\u001b[0;32m     19\u001b[0m     pure_actions\u001b[38;5;241m.\u001b[39mappend(pa)\n\u001b[0;32m     20\u001b[0m     probs\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[1;32m---> 22\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[43magents\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     values\u001b[38;5;241m.\u001b[39mappend(v)\n\u001b[0;32m     25\u001b[0m next_observations, rewards, dones, _, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n",
      "Cell \u001b[1;32mIn[3], line 51\u001b[0m, in \u001b[0;36mAgent.get_value\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     49\u001b[0m     state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray([state]))\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     50\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic\u001b[38;5;241m.\u001b[39mget_value(state)\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "min_actives = 0\n",
    "max_actives = 10_000\n",
    "\n",
    "min_money = 500_000\n",
    "max_money = 1_000_000\n",
    "glass_len = 4\n",
    "state_dim = (glass_len * 2 + 3) * 2\n",
    "action_dim = 3\n",
    "num_agents = 8\n",
    "\n",
    "agents = [Agent(agent_id, random.randint(min_actives, max_actives), random.randint(min_money, max_money), state_dim, action_dim) for agent_id in range(num_agents)]\n",
    "env = MarketSimulation(agents, glass_len)\n",
    "\n",
    "for i in trange(ITERATIONS):\n",
    "        trajectories = sample_episode(env, agents)\n",
    "        \n",
    "        for agent, trajectory in zip(agents, trajectories):\n",
    "            agent.update(trajectory)\n",
    "\n",
    "        if (i + 1) % (ITERATIONS//100) == 0:\n",
    "            rewards = evaluate_policy(env, agents, 5)\n",
    "            print(f\"Step: {i+1}, {rewards}, Reward mean: {np.mean(rewards)}, Reward std: {np.std(rewards)}\")\n",
    "            \n",
    "            for agent in agents:\n",
    "                agent.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bfaf23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_actives = 0\n",
    "max_actives = 10_000\n",
    "\n",
    "min_money = 500_000\n",
    "max_money = 1_000_000\n",
    "glass_len = 3\n",
    "state_dim = (glass_len * 2 + 3) * 2\n",
    "action_dim = 3\n",
    "\n",
    "class DemoAgent:\n",
    "    def __init__(self, agent_id):\n",
    "        self.agent_id = agent_id\n",
    "        self.actives = random.randint(min_actives, max_actives)\n",
    "        self.money = random.randint(min_money, max_money)\n",
    "        \n",
    "        self.open = False\n",
    "        self.request = None\n",
    "        self.num_iterations = None\n",
    "        \n",
    "        self.model = torch.load(f\"./agent_{agent_id}.pkl\")\n",
    "        \n",
    "    def act(self, state):\n",
    "        state = torch.tensor(np.array([state]), device=device).float()\n",
    "        action = self.model.act(state)[0]\n",
    "        return action.cpu().numpy()[0]\n",
    "\n",
    "    def reset(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6aeed3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "num_agents = 10\n",
    "\n",
    "agents_demo = [DemoAgent(agent_id) for agent_id in range(num_agents)]\n",
    "env_demo = MarketSimulation(agents_demo, glass_len, render_mode='human')\n",
    "\n",
    "observations = env_demo.reset()\n",
    "\n",
    "try:\n",
    "    for ep in range(50):\n",
    "        actions = []\n",
    "        for i in range(len(agents_demo)):\n",
    "            a = agents_demo[i].act(observations[i])\n",
    "            actions.append((agents_demo[i].agent_id, a))\n",
    "\n",
    "        next_observations, rewards, dones, _, _ = env_demo.step(actions)\n",
    "        observations = next_observations if not any(dones) else env_demo.reset(options=get_options(dones))\n",
    "        print(ep)\n",
    "except KeyboardInterrupt:\n",
    "    env_demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea4db90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>NO</th>\n",
       "      <th>SECCODE</th>\n",
       "      <th>BUYSELL</th>\n",
       "      <th>TIME</th>\n",
       "      <th>ORDERNO</th>\n",
       "      <th>ACTION</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>VOLUME</th>\n",
       "      <th>TRADENO</th>\n",
       "      <th>TRADEPRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20140901</td>\n",
       "      <td>2</td>\n",
       "      <td>SBER</td>\n",
       "      <td>S</td>\n",
       "      <td>100000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>74.18</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20140901</td>\n",
       "      <td>3</td>\n",
       "      <td>SBER</td>\n",
       "      <td>S</td>\n",
       "      <td>100000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>74.75</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20140901</td>\n",
       "      <td>33</td>\n",
       "      <td>SBER</td>\n",
       "      <td>B</td>\n",
       "      <td>100000000</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>73.16</td>\n",
       "      <td>500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20140901</td>\n",
       "      <td>57</td>\n",
       "      <td>SBER</td>\n",
       "      <td>B</td>\n",
       "      <td>100000000</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>71.33</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20140901</td>\n",
       "      <td>83</td>\n",
       "      <td>SBER</td>\n",
       "      <td>S</td>\n",
       "      <td>100000000</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "      <td>74.80</td>\n",
       "      <td>70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20140901</td>\n",
       "      <td>84</td>\n",
       "      <td>SBER</td>\n",
       "      <td>S</td>\n",
       "      <td>100000000</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>74.40</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20140901</td>\n",
       "      <td>85</td>\n",
       "      <td>SBER</td>\n",
       "      <td>S</td>\n",
       "      <td>100000000</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>74.00</td>\n",
       "      <td>50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20140901</td>\n",
       "      <td>86</td>\n",
       "      <td>SBER</td>\n",
       "      <td>S</td>\n",
       "      <td>100000000</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>73.60</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20140901</td>\n",
       "      <td>87</td>\n",
       "      <td>SBER</td>\n",
       "      <td>B</td>\n",
       "      <td>100000000</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>72.80</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20140901</td>\n",
       "      <td>101</td>\n",
       "      <td>SBER</td>\n",
       "      <td>B</td>\n",
       "      <td>100000000</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>72.60</td>\n",
       "      <td>3300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DATE   NO SECCODE BUYSELL       TIME  ORDERNO  ACTION  PRICE  VOLUME  \\\n",
       "0  20140901    2    SBER       S  100000000        2       1  74.18    1500   \n",
       "1  20140901    3    SBER       S  100000000        3       1  74.75    1500   \n",
       "2  20140901   33    SBER       B  100000000       33       1  73.16     500   \n",
       "3  20140901   57    SBER       B  100000000       57       1  71.33    6000   \n",
       "4  20140901   83    SBER       S  100000000       83       1  74.80      70   \n",
       "5  20140901   84    SBER       S  100000000       84       1  74.40      60   \n",
       "6  20140901   85    SBER       S  100000000       85       1  74.00      50   \n",
       "7  20140901   86    SBER       S  100000000       86       1  73.60      40   \n",
       "8  20140901   87    SBER       B  100000000       87       1  72.80      10   \n",
       "9  20140901  101    SBER       B  100000000      101       1  72.60    3300   \n",
       "\n",
       "   TRADENO  TRADEPRICE  \n",
       "0      NaN         NaN  \n",
       "1      NaN         NaN  \n",
       "2      NaN         NaN  \n",
       "3      NaN         NaN  \n",
       "4      NaN         NaN  \n",
       "5      NaN         NaN  \n",
       "6      NaN         NaN  \n",
       "7      NaN         NaN  \n",
       "8      NaN         NaN  \n",
       "9      NaN         NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = './SBER.txt'\n",
    "data = pd.read_csv(file_name)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4de1dec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "      <th>VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73.16</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>71.33</td>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>72.80</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>72.60</td>\n",
       "      <td>3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>73.03</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>72.53</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>72.93</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>70.21</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>70.10</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>73.50</td>\n",
       "      <td>23000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRICE  VOLUME\n",
       "2   73.16     500\n",
       "3   71.33    6000\n",
       "8   72.80      10\n",
       "9   72.60    3300\n",
       "12  73.03     500\n",
       "13  72.53      40\n",
       "24  72.93     500\n",
       "26  70.21  200000\n",
       "28  70.10      80\n",
       "29  73.50   23000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_buy = data[['PRICE', 'VOLUME']].loc[data['BUYSELL'] == 'B']\n",
    "slice_buy[:4407760].to_csv('./SBER_slice_buy.txt', index=False)\n",
    "slice_buy.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c497a062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "      <th>VOLUME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74.18</td>\n",
       "      <td>-1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74.75</td>\n",
       "      <td>-1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.80</td>\n",
       "      <td>-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74.40</td>\n",
       "      <td>-60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74.00</td>\n",
       "      <td>-50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>73.60</td>\n",
       "      <td>-40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>73.70</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>73.58</td>\n",
       "      <td>-250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>74.72</td>\n",
       "      <td>-210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>74.79</td>\n",
       "      <td>-420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PRICE  VOLUME\n",
       "0   74.18   -1500\n",
       "1   74.75   -1500\n",
       "4   74.80     -70\n",
       "5   74.40     -60\n",
       "6   74.00     -50\n",
       "7   73.60     -40\n",
       "10  73.70     -10\n",
       "11  73.58    -250\n",
       "14  74.72    -210\n",
       "15  74.79    -420"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_sell = data[['PRICE', 'VOLUME']].loc[data['BUYSELL'] == 'S']\n",
    "slice_sell['VOLUME'] = -slice_sell['VOLUME']\n",
    "slice_sell.to_csv('./SBER_slice_sell.txt', index=False)\n",
    "slice_sell.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ff8acd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4407760, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_sell.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "725c1729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4573737, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice_buy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cc5376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
